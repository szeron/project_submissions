{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Capstone Project - Wine Recommender System <br> [Part 2 of 3]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "4oQlBkKIzq5F"
   },
   "source": [
    "## Contents:\n",
    "- [Modeling](##Modeling)\n",
    "- [Hyperparameter Tuning](##Hyperparameter-Tuning)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "gDgLbO48JwJX"
   },
   "source": [
    "---\n",
    "## Modeling\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from surprise import Dataset, Reader, accuracy\n",
    "from surprise.model_selection import cross_validate, KFold, GridSearchCV\n",
    "from surprise import NormalPredictor, BaselineOnly, KNNBasic, KNNWithMeans, KNNWithZScore, KNNBaseline, SVD, NMF, CoClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "iaRZZCcTKq5s"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/wine_reviews_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign a unique ID to each wine\n",
    "df['wine_id'] = df.index\n",
    "\n",
    "# Assign a unique ID to each taster\n",
    "taster_ids = df['taster_name'].drop_duplicates().reset_index(drop=True)\n",
    "df['user_id'] = df['taster_name'].map(lambda taster: taster_ids[taster_ids == taster].index[0])\n",
    "\n",
    "# Convert the dataframe to a user preferences format\n",
    "user_prefs = df[['user_id', 'wine_id', 'points']]\n",
    "\n",
    "# Save user preferences dataframe\n",
    "user_prefs[['user_id', 'wine_id', 'points']].to_csv(\"../data/user_prefs.csv\", index=False)\n",
    "\n",
    "# Load data\n",
    "reader = Reader(line_format='user item rating', sep=',', rating_scale=(90, 100), skip_lines=1)\n",
    "data = Dataset.load_from_file(\"../data/user_prefs.csv\", reader=reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the algorithms\n",
    "algorithms = [\n",
    "    ('Normal Predictor', NormalPredictor()),\n",
    "    ('Baseline Predictor', BaselineOnly()),\n",
    "    ('KNN Basic', KNNBasic()),\n",
    "    ('KNN with Means', KNNWithMeans()),\n",
    "    ('KNN with Z-score', KNNWithZScore()),\n",
    "    ('KNN Baseline', KNNBaseline()),\n",
    "    ('SVD', SVD()),\n",
    "    ('Non-negative Matrix Factorization', NMF()),\n",
    "    ('Co-Clustering', CoClustering()),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Fold Cross-Validation\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=random.seed(42))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The threshold value determines the benchmark for wines to be considered relevant. A low threshold means that even wines with lower ratings will be considered relevant, while a high threshold requires wines to have higher ratings to be considered relevant. \n",
    "\n",
    "When the threshold is low, precision might be high because many wines are considered relevant, but recall might be lower because fewer relevant wines are included in the top k recommendations. \n",
    "\n",
    "When the threshold is high, precision might be lower because only a few wines meet the high rating requirement, but recall might be higher because more of the relevant wines are included in the top k recommendations.\n",
    "- `Precision@k` : Proportion of relevant wines among the top k recommendations\n",
    "- `Recall@k` : Proportion of relevant wines among the top k recommendations out of all the relevant wines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Precision@k and Recall@k\n",
    "def precision_recall_at_k(predictions, k=10, threshold=91):\n",
    "    user_est_true = dict()\n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        if uid not in user_est_true:\n",
    "            user_est_true[uid] = []\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "\n",
    "    precisions = dict()\n",
    "    recalls = dict()\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
    "        n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold))\n",
    "                              for (est, true_r) in user_ratings[:k])\n",
    "\n",
    "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 1\n",
    "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 1\n",
    "\n",
    "    return precisions, recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Normal Predictor...\n",
      "Evaluating Baseline Predictor...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Evaluating KNN Basic...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating KNN with Means...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating KNN with Z-score...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating KNN Baseline...\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating SVD...\n",
      "Evaluating Non-negative Matrix Factorization...\n",
      "Evaluating Co-Clustering...\n"
     ]
    }
   ],
   "source": [
    "# Evaluate algorithms\n",
    "results = []\n",
    "for name, algo in algorithms:\n",
    "    print(f\"Evaluating {name}...\")\n",
    "    algo_results = cross_validate(algo, data, measures=['RMSE'], cv=k_fold, verbose=False)\n",
    "    rmse = algo_results['test_rmse'].mean()\n",
    "\n",
    "    # Precision and Recall\n",
    "    precisions_list = []\n",
    "    recalls_list = []\n",
    "    for trainset, testset in k_fold.split(data):\n",
    "        algo.fit(trainset)\n",
    "        predictions = algo.test(testset)\n",
    "        precisions, recalls = precision_recall_at_k(predictions, k=10, threshold=91)\n",
    "\n",
    "        precisions_list.append(sum(prec for prec in precisions.values()) / len(precisions))\n",
    "        recalls_list.append(sum(rec for rec in recalls.values()) / len(recalls))\n",
    "\n",
    "    precision = sum(precisions_list) / len(precisions_list)\n",
    "    recall = sum(recalls_list) / len(recalls_list)\n",
    "\n",
    "    results.append({\n",
    "        'Algorithm': name,\n",
    "        'RMSE': rmse,\n",
    "        'Precision@k': precision,\n",
    "        'Recall@k': recall,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Algorithm      RMSE  Precision@k  Recall@k\n",
      "0                   Normal Predictor  2.175808     0.568371  0.192018\n",
      "1                 Baseline Predictor  1.614335     0.722982  0.106865\n",
      "2                          KNN Basic  1.632080     0.590877  0.195258\n",
      "3                     KNN with Means  1.632050     0.589064  0.210714\n",
      "4                   KNN with Z-score  1.632015     0.596825  0.188387\n",
      "5                       KNN Baseline  1.614353     0.733534  0.093825\n",
      "6                                SVD  1.614460     0.756316  0.077905\n",
      "7  Non-negative Matrix Factorization  1.632030     0.570994  0.186223\n",
      "8                      Co-Clustering  1.632060     0.564486  0.185423\n"
     ]
    }
   ],
   "source": [
    "# Display the results\n",
    "results = pd.DataFrame(results)\n",
    "results = results[['Algorithm', 'RMSE', 'Precision@k', 'Recall@k']]\n",
    "print(results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will choose the SVD algorithm for tuning as it has the one of the lowest RMSE scores and the highest Precision@k score."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparameters for SVD\n",
    "param_grid = {\n",
    "    'n_factors': [150],                 # [50, 100, 150] \n",
    "    'n_epochs': [40],                   # [20, 30, 40]  \n",
    "    'lr_all': [0.005],                  # [0.001, 0.002, 0.005] \n",
    "    'reg_all': [0.005],                 # [0.005, 0.05, 0.1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSE score of tuned SVD model is 1.614552\n",
      "Best parameters of tuned SVD model are {'n_factors': 150, 'n_epochs': 40, 'lr_all': 0.005, 'reg_all': 0.005}\n"
     ]
    }
   ],
   "source": [
    "# Instantiate and fit tuned SVD model using GridSearchCV\n",
    "grid_search = GridSearchCV(SVD, param_grid, measures=['rmse'], cv=3, n_jobs=-1)\n",
    "grid_search.fit(data)\n",
    "\n",
    "print(f'Best RMSE score of tuned SVD model is {round(grid_search.best_score[\"rmse\"],6)}')\n",
    "print(f'Best parameters of tuned SVD model are {grid_search.best_params[\"rmse\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_params' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Train the SVD model with the best hyperparameters\u001b[39;00m\n\u001b[1;32m      2\u001b[0m tuned_svd \u001b[39m=\u001b[39m SVD(\n\u001b[0;32m----> 3\u001b[0m     n_factors\u001b[39m=\u001b[39mbest_params[\u001b[39m'\u001b[39m\u001b[39mn_factors\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m      4\u001b[0m     n_epochs\u001b[39m=\u001b[39mbest_params[\u001b[39m'\u001b[39m\u001b[39mn_epochs\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m      5\u001b[0m     lr_all\u001b[39m=\u001b[39mbest_params[\u001b[39m'\u001b[39m\u001b[39mlr_all\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m      6\u001b[0m     reg_all\u001b[39m=\u001b[39mbest_params[\u001b[39m'\u001b[39m\u001b[39mreg_all\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m      7\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'best_params' is not defined"
     ]
    }
   ],
   "source": [
    "# Train the SVD model with the best hyperparameters\n",
    "tuned_svd = SVD(\n",
    "    n_factors=best_params['n_factors'],\n",
    "    n_epochs=best_params['n_epochs'],\n",
    "    lr_all=best_params['lr_all'],\n",
    "    reg_all=best_params['reg_all'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the SVD model with the best hyperparameters\n",
    "tuned_svd = SVD(\n",
    "    n_factors=grid_search.best_params[\"rmse\"][\"n_factors\"],\n",
    "    n_epochs=grid_search.best_params[\"rmse\"][\"n_epochs\"],\n",
    "    lr_all=grid_search.best_params[\"rmse\"][\"lr_all\"],\n",
    "    reg_all=grid_search.best_params[\"rmse\"][\"reg_all\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned SVD model:\n",
      "Precision@k: 0.7442\n",
      "Recall@k: 0.0750\n"
     ]
    }
   ],
   "source": [
    "# Precision and Recall\n",
    "k_fold = KFold(n_splits=5)\n",
    "precisions_list = []\n",
    "recalls_list = []\n",
    "\n",
    "for trainset, testset in k_fold.split(data):\n",
    "    tuned_svd.fit(trainset)\n",
    "    predictions = tuned_svd.test(testset)\n",
    "    precisions, recalls = precision_recall_at_k(predictions, k=10, threshold=91)\n",
    "\n",
    "    precisions_list.append(sum(prec for prec in precisions.values()) / len(precisions))\n",
    "    recalls_list.append(sum(rec for rec in recalls.values()) / len(recalls))\n",
    "\n",
    "precision = sum(precisions_list) / len(precisions_list)\n",
    "recall = sum(recalls_list) / len(recalls_list)\n",
    "\n",
    "print(f\"Tuned SVD model:\")\n",
    "print(f\"Precision@k: {precision:.4f}\")\n",
    "print(f\"Recall@k: {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Threshold  Precision@k  Recall@k  F1-score\n",
      "0         90     1.000000  0.195189  0.326624\n",
      "1         91     0.772982  0.066032  0.121671\n",
      "2         92     0.980000  0.053176  0.100879\n"
     ]
    }
   ],
   "source": [
    "thresholds = [90, 91, 92]\n",
    "\n",
    "results = []\n",
    "for threshold in thresholds:\n",
    "    k_fold = KFold(n_splits=5)\n",
    "    precisions_list = []\n",
    "    recalls_list = []\n",
    "\n",
    "    for trainset, testset in k_fold.split(data):\n",
    "        tuned_svd.fit(trainset)\n",
    "        predictions = tuned_svd.test(testset)\n",
    "        precisions, recalls = precision_recall_at_k(predictions, k=10, threshold=threshold)\n",
    "\n",
    "        precisions_list.append(sum(prec for prec in precisions.values()) / len(precisions))\n",
    "        recalls_list.append(sum(rec for rec in recalls.values()) / len(recalls))\n",
    "\n",
    "    precision = sum(precisions_list) / len(precisions_list)\n",
    "    recall = sum(recalls_list) / len(recalls_list)\n",
    "    results.append({\n",
    "        'Threshold': threshold,\n",
    "        'Precision@k': precision,\n",
    "        'Recall@k': recall,\n",
    "    })\n",
    "\n",
    "# Display the results\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Calculate F1-score\n",
    "results_df['F1-score'] = 2 * (results_df['Precision@k'] * results_df['Recall@k']) / (results_df['Precision@k'] + results_df['Recall@k'])\n",
    "\n",
    "results_df = results_df[['Threshold', 'Precision@k', 'Recall@k', 'F1-score']]\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Recommendations for the New User:\n",
      "   wine_id  estimated_rating  \\\n",
      "0        0         91.699629   \n",
      "1        1         91.699629   \n",
      "2        2         91.699629   \n",
      "3        3         91.699629   \n",
      "4        4         91.699629   \n",
      "5        5         91.699629   \n",
      "6        6         91.699629   \n",
      "7        7         91.699629   \n",
      "8        8         91.699629   \n",
      "9        9         91.699629   \n",
      "\n",
      "                                               title  points  \n",
      "0  Dopff & Irion 2004 Schoenenbourg Grand Cru Ven...      92  \n",
      "1         Ceretto 2003 Bricco Rocche Prap√≥  (Barolo)      92  \n",
      "2  Matrix 2007 Stuhlmuller Vineyard Chardonnay (A...      92  \n",
      "3  Mauritson 2007 Rockpile Cemetary Vineyard Zinf...      92  \n",
      "4    Silverado 2006 Cabernet Sauvignon (Napa Valley)      92  \n",
      "5  Le Riche 2003 Cabernet Sauvignon Reserve Caber...      91  \n",
      "6  Pierre Sparr 2007 Vendages Tardives Gewurztram...      91  \n",
      "7        Pierre Sparr 2008 Alsace One White (Alsace)      91  \n",
      "8               Kuentz-Bas 2008 Pinot Blanc (Alsace)      91  \n",
      "9  Camberley 2004 Philosophers' Stone Red (Stelle...      91  \n"
     ]
    }
   ],
   "source": [
    "# Create a new user ID\n",
    "new_user_id = df['user_id'].max() + 1\n",
    "\n",
    "# Create a list of all wine_ids\n",
    "wine_ids = df['wine_id'].unique()\n",
    "\n",
    "# Generate predicted ratings for the new user for each wine\n",
    "predicted_ratings = []\n",
    "for wine_id in wine_ids:\n",
    "    predicted_rating = tuned_svd.predict(new_user_id, wine_id)\n",
    "    predicted_ratings.append((wine_id, predicted_rating.est))\n",
    "\n",
    "# Sort the wines based on the predicted ratings\n",
    "sorted_predicted_ratings = sorted(predicted_ratings, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Retrieve the top 10 recommendations\n",
    "top_10_recommendations = sorted_predicted_ratings[:10]\n",
    "\n",
    "# Compare the estimated ratings to the actual ratings\n",
    "recommended_wines = pd.DataFrame(top_10_recommendations, columns=['wine_id', 'estimated_rating'])\n",
    "recommended_wines = recommended_wines.merge(df[['wine_id', 'title', 'points']], on='wine_id')\n",
    "\n",
    "print(\"Top 10 Recommendations for the New User:\")\n",
    "print(recommended_wines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of wines with desired trait(s): 34\n",
      "Top 10 Recommendations for new user with Desired Traits:\n",
      "   wine_id  estimated_rating  \\\n",
      "0    56832         91.699629   \n",
      "1    44425         91.699629   \n",
      "2    50263         91.699629   \n",
      "3     9067         91.699629   \n",
      "4    32077         91.699629   \n",
      "5    32085         91.699629   \n",
      "6    41327         91.699629   \n",
      "7     2696         91.699629   \n",
      "8    30428         91.699629   \n",
      "9    27036         91.699629   \n",
      "\n",
      "                                               title  points  \n",
      "0        La Ca' Nova 2016 Montestefano  (Barbaresco)      97  \n",
      "1  Nino Negri 2013 5 Stelle  (Sforzato di Valtell...      95  \n",
      "2               Le Gode 2012  Brunello di Montalcino      95  \n",
      "3       Le Ragnaie 2012 VV  (Brunello di Montalcino)      95  \n",
      "4              Bruno Giacosa 2011 Falletto  (Barolo)      95  \n",
      "5          Cavallotto 2009 Vignolo Riserva  (Barolo)      95  \n",
      "6       Le Ragnaie 2012 VV  (Brunello di Montalcino)      95  \n",
      "7  Nino Negri 2013 5 Stelle  (Sforzato di Valtell...      95  \n",
      "8               Le Gode 2012  Brunello di Montalcino      95  \n",
      "9           Giacomo Conterno 2011 Cerretta  (Barolo)      94  \n"
     ]
    }
   ],
   "source": [
    "# Define the traits\n",
    "desired_traits = {'full-bodied', 'cherry', 'tobacco', 'cinnamon'}\n",
    "\n",
    "# Sort wines by points in descending order\n",
    "df_sorted = df.sort_values('points', ascending=False)\n",
    "\n",
    "# Filter wines based on desired traits\n",
    "filtered_wines = df_sorted[df_sorted['tokens'].apply(lambda tokens: all(trait in tokens for trait in desired_traits))]\n",
    "\n",
    "print(\"Number of wines with desired trait(s):\", len(filtered_wines))\n",
    "\n",
    "# Generate predicted ratings for the new user for each filtered wine\n",
    "predicted_ratings = []\n",
    "for wine_id in filtered_wines['wine_id']:\n",
    "    predicted_rating = tuned_svd.predict(new_user_id, wine_id)\n",
    "    predicted_ratings.append((wine_id, predicted_rating.est))\n",
    "\n",
    "# Sort the wines based on the predicted ratings\n",
    "sorted_predicted_ratings = sorted(predicted_ratings, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Retrieve the top 10 recommendations\n",
    "top_10_recommendations = sorted_predicted_ratings[:10]\n",
    "\n",
    "# Compare the estimated ratings to the actual ratings\n",
    "recommended_wines = pd.DataFrame(top_10_recommendations, columns=['wine_id', 'estimated_rating'])\n",
    "recommended_wines = recommended_wines.merge(df[['wine_id', 'title', 'points']], on='wine_id')\n",
    "\n",
    "# Sort by 'points' in descending order\n",
    "recommended_wines = recommended_wines.sort_values(by='points', ascending=False)\n",
    "\n",
    "print(\"Top 10 Recommendations for new user with Desired Traits:\")\n",
    "print(recommended_wines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "72a51f30bf8c483e1fc0abe989f81cc66824b206d24365642f1a7e7f70f5a428"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
